---
title: "running_ER_on_cluster"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{running_ER_on_cluster}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteKeyword{PDF}
  %\VignetteKeyword{HTML}
  %\VignetteKeyword{vignette}
  %\VignetteKeyword{package}
  
  # %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
library(formatR)
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

## Vignette from the ER repository

<https://github.com/Hanxi-002/EssReg/blob/main/EssRegVignette_pipeline.pdf>

### Install development version

```{r setup, eval = F, tidy=TRUE, tidy.opts=list(width.cutoff=60)}
library(devtools)

# Note: if you submit an array job that calls this function in quick succession,
# you'll get rate limited and error out.

# run this to install 
devtools::install_github(repo = "TranscriptionFactory/JishnuLabTools", force = F,
                         dependencies = T)

library(JishnuLabTools)
```

### Data format should be saved as a csv or rds file as one of these:

-   Separate X and Y

-   Combined X and Y where Y is the first column

### Get example yaml files

You can edit these files to have the paths to your X and Y data by using the list accessors (e.g. regression\$x_path = 'path to x') or you can just save the yaml and edit it.

Note the output path should always end in "/"

### Example regression yaml

```{r example_yaml_reg, eval = F}

regression = JishnuLabTools::regression_params
knitr::kable(data.frame(regression_parameters = unlist(regression)))
```

### Example classification yaml

```{r example_yaml_class, eval = T}

classification = JishnuLabTools::classification_params

# this is just for printing here
classification$y_levels = "[0, 1]"
knitr::kable(data.frame(classification_parameters = unlist(classification)))

```

### If you want to run a coarse grid search over specific (as opposed to the predfined) deltas and lambdas, the yaml file 
### should have a list of values for delta and lambda, like this:
```{r example_yaml_class_coarseGrid, eval = T}

classification = JishnuLabTools::classification_params

# this is just for printing here
classification$y_levels = "[0, 1]"
classification$delta = "[0.1, 0.05, 0.01]"
classification$lambda = "[1.0, 0.1]"
knitr::kable(data.frame(classification_parameters = unlist(classification)))

```

## Save the proper yaml file somewhere

```{r save_yaml, eval = F}

classification$x_path = 'x.csv'
classification$y_path = 'y.csv'
classification$out_path = '/'

yaml::write_yaml(classification, 'where_you_want_to_save_yaml_file')

```




### Slurm script for single submission (put your email into --mail-user=)

```{r slurm_script, eval = F}

#!/bin/bash
#SBATCH -t 3-00:00
#SBATCH --job-name= ER
#SBATCH --mail-user=
#SBATCH --mail-type=FAIL
#SBATCH --nodes=1
#SBATCH --ntasks=1
#SBATCH --mem=150g
#SBATCH --cpus-per-task=16

module load gcc/10.2.0
module load r/4.2.0

Rscript runER.R --yaml_path 'path_to_yaml' --coarse_grid F 

```

### Example Script 1: Save this as runER.R or whatever comes after Rscript above
```{r runER, eval = F, tidy=TRUE, tidy.opts=list(width.cutoff=60)}
#!/usr/bin/env Rscript
args = commandArgs(trailingOnly=TRUE)

library(devtools)
library(doParallel)
library(foreach)
library(tidyverse)

# if need to install
devtools::install_github(repo = "TranscriptionFactory/JishnuLabTools", force = F, dependencies = T)

library(JishnuLabTools)

cores <-  as.numeric(Sys.getenv('SLURM_CPUS_PER_TASK', unset=NA))
if(is.na(cores)) cores <- detectCores()
# if(!is.na(cores) & cores > 1) cores <- cores
registerDoParallel(cores)
cat('number of cores using', cores, '. . .\n')


# process arguments from command line
command_args = optparse::parse_args(optparse::OptionParser(option_list = JishnuLabTools::runER_args), args = args)

yaml_path = command_args$yaml_path
coarseGrid = command_args$coarse_grid

# call ER function
JishnuLabTools::runER(yaml_path, coarseGrid)

```

### Example Script 2: call EssReg functions directly
```{r essreg, eval = F}
#!/usr/bin/env Rscript
args = commandArgs(trailingOnly=TRUE)

library(devtools)
library(doParallel)
library(foreach)
library(tidyverse)

# if need to install
devtools::install_github(repo = "TranscriptionFactory/JishnuLabTools", force = F, dependencies = T)

library(JishnuLabTools)

cores <-  as.numeric(Sys.getenv('SLURM_CPUS_PER_TASK', unset=NA))
if(is.na(cores)) cores <- detectCores()
# if(!is.na(cores) & cores > 1) cores <- cores
registerDoParallel(cores)
cat('number of cores using', cores, '. . .\n')

# process arguments from command line
command_args = optparse::parse_args(optparse::OptionParser(option_list = JishnuLabTools::runER_args), args = args)

yaml_path = command_args$yaml_path

# pipeline 1
EssReg::pipelineER1(yaml_path)

# pipeline 2
EssReg::pipelineER2(yaml_path)

# pipeline 3
EssReg::pipelineER3(yaml_path)
```

### Slurm batch submission

You want to point to a folder with yaml files or dataframes (combined X/Y)
Note, you should comment out the `install_github()` in the runER.R file so that you don't get rate
limited
```{r slurm_array, eval = F}
#!/bin/bash
#SBATCH -t 3-00:00
#SBATCH --array= numbers
#SBATCH --job-name= ER
#SBATCH --mail-user=aar126@pitt.edu
#SBATCH --mail-type=FAIL
#SBATCH --nodes=1
#SBATCH --ntasks=1
#SBATCH --mem=150g
#SBATCH --cpus-per-task=16


echo "SLURM_JOBID: " $SLURM_JOBID
echo "SLURM_ARRAY_TASK_ID: " $SLURM_ARRAY_TASK_ID
echo "SLURM_ARRAY_JOB_ID: " $SLURM_ARRAY_JOB_ID

cd 'path to where you have yaml files'

arrayfile=`ls | awk -v line=$SLURM_ARRAY_TASK_ID '{if (NR == line) print $0}'`

module load gcc/10.2.0
module load r/4.2.0
echo $arrayfile
# usage: Rscript -d datapath_from_working_dir_including_extension
Rscript runER.R --yaml_path $arrayfile --coarse_grid F

```
